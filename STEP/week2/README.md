# Week2 Homework

## 宿題1: week2_1.py

` python week2_1.py -n [検証するNの最大値]` で実行

2 ≦ N ≦ (指定した値)である自然数Nに対して、N次正方行列の積について計算を実行し、かかった時間をグラフに表示

## 宿題4: week2_4.py

` python week2_4.py`
で実行するだけです

考え方は以下の通りです(宿題3)

>初めは辞書を使わずに実装していたのですが、今回空間計算量もO(X)との制限があり、  
>そうすると配列を使って自分でハッシュテーブルを実装した際に、idとして、
>キャッシュのサイズ以下の数字（４なら0~3)sしかとれないので、衝突がおきまくってしまい、  
>結局、実質としては時間計算量がO(1)になりません。  
>slackでのはらけんさんの話から辞書は使って良さそうだったので辞書を使うことにしました。  
>辞書はサイズを大きくとらなくてもkeyの値が飛び飛びで使えるためです.  
>(つまり、空間計算量の制限を守りつつ、衝突が起きる確率を下げることができる）  
>　  
>まず、urlをハッシュ関数でkeyに変換し、その場所にwebページを格納することで、キャッシュを実現します。  
>ところがこれだと、追加された順序が管理できていません。  
>その時に組み合わせるデータ構造として思いついたのはリスト（キュー）です。  
>これは追加した順番に要素を取り出していくことができます。  
>ところが、問題は、「すでにurlがキャッシュに存在するときに、そのページにアクセスした際、先頭に移動させる」  
>という機能を、O(1)で実現しないといけないことです。  
>こうなると、リストの中でどこにそのurlがあるかというのを調べなければならず、  
>リスト内におけるその要素のindexを取得する(list.index('a.com')のような形)には、  
>リストを順番に見ていって、何番目が一致しているかを調べるので、最悪O(X)の時間がかかると思います。  
>であれば、リストの何番目に格納されているかを、  
>ハッシュテーブルに一緒に格納しておけばいいのではないかと考えたのですが、    
>そうすると、リストのn番目から要素を取り出して先頭に移動した際に、  
>他の要素のindexも1ずつずれてしまい、それを書き換えるのに最悪O(X)の時間がかかります。  
>したがってこの方法も使えないことがわかりました。  
>
>そこで考えたのが、各urlに対して、「親url」および「子url」の情報をハッシュテーブルに格納するという考え方です。  
>また、最古・最新のurlは、self.oldestおよびself.newestに随時記録しておきます。  
>こうすることで、n番目の要素を取り出して先頭に移動する際にも、その前後のn-1番目とn番目のノードのみ、  
>親子関係を修正すればすみます。  
>
>これを実装したのがweek2_4.pyになるのですが、  
>各keyに値が4つ格納されているので、厳密には空間計算量はO(4X)ですが、定数係数は無視するのでこれで勘弁、  
>という感じです・・・  
